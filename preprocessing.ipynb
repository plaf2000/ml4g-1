{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e1d3c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import parameters\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d5ffdc2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters.KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d246a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "header = [\"chr\", \"start\", \"end\", \"name\", \"score\", \"strand\", \"signalValue\", \"pValue\", \"qValue\", \"peak\"]\n",
    "all_chroms = {f\"chr{i}\" for i in range(1, 23)}\n",
    "B = {\"chr14\", \"chr19\"}\n",
    "C = {\"chr1\"}\n",
    "A = all_chroms - B - C\n",
    "\n",
    "\n",
    "def bed_dataset_statistics(train_or_val):\n",
    "    data = {}\n",
    "    sorted_indexes = {}\n",
    "\n",
    "    n_sorted_indexes = 100\n",
    "\n",
    "\n",
    "    for cell_type in [\"X1\", \"X2\"]:\n",
    "        df = pd.read_csv(f\"Data/CAGE-train/{cell_type}_{train_or_val}_info.tsv\", sep=\"\\t\") #, index_col=\"gene_name\")\n",
    "\n",
    "        mask = df['strand'] == '-'\n",
    "        df.loc[mask, ['TSS_start', 'TSS_end', 'gene_start', 'gene_end']] = df.loc[mask, ['TSS_end', 'TSS_start', 'gene_end', 'gene_start']].values\n",
    "        df = df.drop(columns=['strand'])\n",
    "\n",
    "        data[cell_type] = np.zeros((len(df), parameters.N_BEDS, parameters.KNN, parameters.N_FEATURES_BED))\n",
    "        sorted_indexes[cell_type] = -np.ones((len(df), parameters.N_BEDS, n_sorted_indexes), dtype=int)\n",
    "        \n",
    "        for signal_index, signal in enumerate(os.listdir(\"Data/bed/\")):\n",
    "            bed = pd.read_csv(f\"Data/bed/{signal}/{cell_type}.bed\", names=header, sep=\"\\t\")\n",
    "            bed[\"center\"] = (bed[\"start\"] + bed[\"end\"]) // 2\n",
    "\n",
    "            # joined_df = df.merge(bed, on=\"chr\", how=\"inner\", suffixes=('_train', '_bed'))\n",
    "            # joined_df[\"distance\"] = np.abs(joined_df[\"center\"] - joined_df[\"TSS_start\"])\n",
    "            # joined_df = joined_df.groupby(\"gene_name\").apply(lambda x: x.nsmallest(parameters.KNN, \"distance\"))\n",
    "            # print(joined_df.head())\n",
    "\n",
    "            for row_index, row in tqdm(df.iterrows(), total=len(df)):\n",
    "                chr = row[\"chr\"]\n",
    "                TSS_start = row[\"TSS_start\"]\n",
    "                same_chromosome = bed[bed[\"chr\"] == chr].copy()\n",
    "                same_chromosome[\"dist\"] = np.abs(same_chromosome[\"center\"] - TSS_start)\n",
    "                closest_indexes = np.argsort(same_chromosome[\"dist\"])[:n_sorted_indexes]\n",
    "                knn = same_chromosome.iloc[closest_indexes[:parameters.KNN]].copy()\n",
    "                knn[\"rel_pos_TSS_end\"] = knn[\"center\"] - row[\"TSS_end\"]\n",
    "                knn[\"rel_pos_TSS_start\"] = knn[\"center\"] - row[\"TSS_start\"]\n",
    "                knn[\"rel_pos_gene_start\"] = knn[\"center\"] - row[\"gene_start\"]\n",
    "                knn[\"rel_pos_gene_end\"] = knn[\"center\"] - row[\"gene_end\"]\n",
    "\n",
    "                data[cell_type][row_index, signal_index, :, 0] = knn[\"signalValue\"].values\n",
    "                data[cell_type][row_index, signal_index, :, 1] = knn[\"rel_pos_TSS_start\"].values\n",
    "                data[cell_type][row_index, signal_index, :, 2] = knn[\"rel_pos_TSS_end\"].values\n",
    "                data[cell_type][row_index, signal_index, :, 3] = knn[\"rel_pos_gene_start\"].values\n",
    "                data[cell_type][row_index, signal_index, :, 4] = knn[\"rel_pos_gene_end\"].values\n",
    "                sorted_indexes[cell_type][row_index, signal_index, :len(closest_indexes)] = closest_indexes\n",
    "                \n",
    "    return data, sorted_indexes\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0073ecbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1974/1974 [00:32<00:00, 61.65it/s]\n",
      "100%|██████████| 1974/1974 [00:17<00:00, 110.82it/s]\n",
      "100%|██████████| 1974/1974 [00:28<00:00, 68.84it/s]\n",
      "100%|██████████| 1974/1974 [00:17<00:00, 114.61it/s]\n",
      "100%|██████████| 1974/1974 [00:13<00:00, 151.59it/s]\n",
      "100%|██████████| 1974/1974 [00:12<00:00, 157.85it/s]\n",
      "100%|██████████| 1974/1974 [00:20<00:00, 97.00it/s] \n",
      "100%|██████████| 1974/1974 [00:27<00:00, 71.86it/s]\n",
      "100%|██████████| 1974/1974 [00:55<00:00, 35.79it/s]\n",
      "100%|██████████| 1974/1974 [00:51<00:00, 38.23it/s]\n",
      "100%|██████████| 1974/1974 [00:29<00:00, 66.32it/s]\n",
      "100%|██████████| 1974/1974 [00:29<00:00, 67.76it/s]\n",
      "100%|██████████| 1974/1974 [00:46<00:00, 42.84it/s]\n",
      "100%|██████████| 1974/1974 [00:40<00:00, 48.23it/s]\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'preprocessed/val_bed_data.npz'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m val_data, val_sorted_indexes = bed_dataset_statistics(\u001b[33m\"\u001b[39m\u001b[33mval\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43msavez_compressed\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpreprocessed/val_bed_data.npz\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX1\u001b[49m\u001b[43m=\u001b[49m\u001b[43mval_data\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mX1\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX2\u001b[49m\u001b[43m=\u001b[49m\u001b[43mval_data\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mX2\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m                    \u001b[49m\u001b[43mX1_sorted_indexes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mval_sorted_indexes\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mX1\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX2_sorted_indexes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mval_sorted_indexes\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mX2\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/python/plaf/miniforge3/envs/ml4g/lib/python3.12/site-packages/numpy/lib/_npyio_impl.py:766\u001b[39m, in \u001b[36msavez_compressed\u001b[39m\u001b[34m(file, allow_pickle, *args, **kwds)\u001b[39m\n\u001b[32m    694\u001b[39m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_savez_compressed_dispatcher)\n\u001b[32m    695\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msavez_compressed\u001b[39m(file, *args, allow_pickle=\u001b[38;5;28;01mTrue\u001b[39;00m, **kwds):\n\u001b[32m    696\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    697\u001b[39m \u001b[33;03m    Save several arrays into a single file in compressed ``.npz`` format.\u001b[39;00m\n\u001b[32m    698\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    764\u001b[39m \n\u001b[32m    765\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m766\u001b[39m     \u001b[43m_savez\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_pickle\u001b[49m\u001b[43m=\u001b[49m\u001b[43mallow_pickle\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/python/plaf/miniforge3/envs/ml4g/lib/python3.12/site-packages/numpy/lib/_npyio_impl.py:792\u001b[39m, in \u001b[36m_savez\u001b[39m\u001b[34m(file, args, kwds, compress, allow_pickle, pickle_kwargs)\u001b[39m\n\u001b[32m    789\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    790\u001b[39m     compression = zipfile.ZIP_STORED\n\u001b[32m--> \u001b[39m\u001b[32m792\u001b[39m zipf = \u001b[43mzipfile_factory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mw\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    793\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    794\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m key, val \u001b[38;5;129;01min\u001b[39;00m namedict.items():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/python/plaf/miniforge3/envs/ml4g/lib/python3.12/site-packages/numpy/lib/_npyio_impl.py:112\u001b[39m, in \u001b[36mzipfile_factory\u001b[39m\u001b[34m(file, *args, **kwargs)\u001b[39m\n\u001b[32m    110\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mzipfile\u001b[39;00m\n\u001b[32m    111\u001b[39m kwargs[\u001b[33m'\u001b[39m\u001b[33mallowZip64\u001b[39m\u001b[33m'\u001b[39m] = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m112\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mzipfile\u001b[49m\u001b[43m.\u001b[49m\u001b[43mZipFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/python/plaf/miniforge3/envs/ml4g/lib/python3.12/zipfile/__init__.py:1352\u001b[39m, in \u001b[36mZipFile.__init__\u001b[39m\u001b[34m(self, file, mode, compression, allowZip64, compresslevel, strict_timestamps, metadata_encoding)\u001b[39m\n\u001b[32m   1350\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m   1351\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1352\u001b[39m         \u001b[38;5;28mself\u001b[39m.fp = \u001b[43mio\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilemode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1353\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[32m   1354\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m filemode \u001b[38;5;129;01min\u001b[39;00m modeDict:\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'preprocessed/val_bed_data.npz'"
     ]
    }
   ],
   "source": [
    "val_data, val_sorted_indexes = bed_dataset_statistics(\"val\")\n",
    "np.savez_compressed(\"Data/processed/val_bed_data.npz\", X1=val_data[\"X1\"], X2=val_data[\"X2\"],\n",
    "                    X1_sorted_indexes=val_sorted_indexes[\"X1\"], X2_sorted_indexes=val_sorted_indexes[\"X2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e392342",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14310/14310 [04:48<00:00, 49.57it/s]\n",
      "100%|██████████| 14310/14310 [03:56<00:00, 60.40it/s]\n",
      "100%|██████████| 14310/14310 [03:26<00:00, 69.20it/s] \n",
      "100%|██████████| 14310/14310 [01:47<00:00, 132.71it/s]\n",
      "100%|██████████| 14310/14310 [01:30<00:00, 158.29it/s]\n",
      "100%|██████████| 14310/14310 [01:04<00:00, 220.88it/s]\n",
      "100%|██████████| 14310/14310 [01:50<00:00, 129.60it/s]\n",
      "100%|██████████| 14310/14310 [03:32<00:00, 67.39it/s] \n",
      "100%|██████████| 14310/14310 [04:52<00:00, 48.93it/s]\n",
      "100%|██████████| 14310/14310 [05:04<00:00, 47.00it/s]\n",
      "100%|██████████| 14310/14310 [03:18<00:00, 72.25it/s] \n",
      "100%|██████████| 14310/14310 [02:10<00:00, 109.50it/s]\n",
      "100%|██████████| 14310/14310 [05:58<00:00, 39.90it/s]\n",
      "100%|██████████| 14310/14310 [05:28<00:00, 43.53it/s]\n"
     ]
    }
   ],
   "source": [
    "train_data, train_sorted_indexes = bed_dataset_statistics(\"train\")\n",
    "np.savez_compressed(\"Data/processed/train_bed_data.npz\", X1=train_data[\"X1\"], X2=train_data[\"X2\"],\n",
    "                    X1_sorted_indexes=train_sorted_indexes[\"X1\"], X2_sorted_indexes=train_sorted_indexes[\"X2\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c84cf449",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cell_type in [\"X1\", \"X2\"]:\n",
    "    y_train_df = pd.read_csv(f\"Data/CAGE-train/{cell_type}_train_y.tsv\", sep=\"\\t\") #, index_col=\"gene_name\")\n",
    "    y_train = np.array(y_train_df[\"gex\"].values)\n",
    "    np.save(f\"Data/processed/{cell_type}_train_y.npy\", y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd9a3ed3",
   "metadata": {},
   "source": [
    "Create the train data based on already sorted indexes (which is computationally demanding)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0389844",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14310/14310 [01:55<00:00, 123.85it/s]\n",
      "100%|██████████| 14310/14310 [01:29<00:00, 159.72it/s]\n",
      "100%|██████████| 14310/14310 [02:05<00:00, 114.39it/s]\n",
      "100%|██████████| 14310/14310 [01:17<00:00, 184.49it/s]\n",
      "100%|██████████| 14310/14310 [01:01<00:00, 234.54it/s]\n",
      "100%|██████████| 14310/14310 [00:49<00:00, 291.17it/s]\n",
      "100%|██████████| 14310/14310 [01:38<00:00, 145.51it/s]\n",
      "100%|██████████| 14310/14310 [01:54<00:00, 125.07it/s]\n",
      "100%|██████████| 14310/14310 [03:39<00:00, 65.34it/s]\n",
      "100%|██████████| 14310/14310 [02:44<00:00, 86.84it/s] \n",
      "100%|██████████| 14310/14310 [01:07<00:00, 213.43it/s]\n",
      "100%|██████████| 14310/14310 [00:58<00:00, 245.61it/s]\n",
      "100%|██████████| 14310/14310 [02:06<00:00, 112.89it/s]\n",
      "100%|██████████| 14310/14310 [01:54<00:00, 125.26it/s]\n"
     ]
    }
   ],
   "source": [
    "def process_data(train_or_val):\n",
    "    sorted_indexes = np.load(f\"Data/processed/sorted_indexes.npz\")\n",
    "    data = {}\n",
    "    for cell_type in [\"X1\", \"X2\"]:\n",
    "        indexes = sorted_indexes[cell_type]\n",
    "        df = pd.read_csv(f\"Data/CAGE-train/{cell_type}_{train_or_val}_info.tsv\", sep=\"\\t\") #, index_col=\"gene_name\")\n",
    "        data[cell_type] = np.zeros((len(df), parameters.N_BEDS, parameters.KNN, 5))\n",
    "\n",
    "        for signal_index, signal in enumerate(os.listdir(\"Data/bed/\")):\n",
    "            bed = pd.read_csv(f\"Data/bed/{signal}/{cell_type}.bed\", names=header, sep=\"\\t\")\n",
    "            bed[\"center\"] = (bed[\"start\"] + bed[\"end\"]) // 2\n",
    "            for row_index, row in tqdm(df.iterrows(), total=len(df)):\n",
    "                knn_indx = indexes[row_index, signal_index, :parameters.KNN]\n",
    "                same_chromosome = bed[bed[\"chr\"] == row[\"chr\"]].copy()\n",
    "                knn = same_chromosome.iloc[knn_indx].copy()\n",
    "                knn[\"rel_pos_TSS_start\"] = knn[\"center\"] - row[\"TSS_start\"]\n",
    "                knn[\"rel_pos_TSS_end\"] = knn[\"center\"] - row[\"TSS_end\"]\n",
    "                knn[\"rel_pos_gene_start\"] = knn[\"center\"] - row[\"gene_start\"]\n",
    "                knn[\"rel_pos_gene_end\"] = knn[\"center\"] - row[\"gene_end\"]\n",
    "\n",
    "                data[cell_type][row_index, signal_index, :, 0] = knn[\"signalValue\"].values\n",
    "                data[cell_type][row_index, signal_index, :, 1] = knn[\"rel_pos_TSS_start\"].values\n",
    "                data[cell_type][row_index, signal_index, :, 2] = knn[\"rel_pos_TSS_end\"].values\n",
    "                data[cell_type][row_index, signal_index, :, 3] = knn[\"rel_pos_gene_start\"].values\n",
    "                data[cell_type][row_index, signal_index, :, 4] = knn[\"rel_pos_gene_end\"].values\n",
    "        \n",
    "\n",
    "\n",
    "                \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e551f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d633d414",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.load(\"Data/train_data.npz\", allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b38689f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32568"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = train_data[\"x\"]\n",
    "X[:, :, 0].mean()\n",
    "len(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34697a81",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af7d972",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DNase', 'H3K4me1', 'H3K4me3', 'H3K27ac', 'H3K36me3']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters.SIGNALS_CNN\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2c65594b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dataframe(df_x, df_y):\n",
    "    # Merge x and y on gene_name\n",
    "    df = pd.merge(df_x, df_y, on='gene_name')\n",
    "\n",
    "    # Invert given the strand\n",
    "    mask = df['strand'] == '-'\n",
    "    df.loc[mask, ['TSS_start', 'TSS_end']] = df.loc[mask, ['TSS_end', 'TSS_start']].values\n",
    "    df = df.drop(columns=['strand'])\n",
    "\n",
    "    # Replace chromosome with numeric values\n",
    "    def chr_to_num(chr_val):\n",
    "        chr_val = chr_val.replace('chr','')\n",
    "        return int(chr_val)\n",
    "    df['chr'] = df['chr'].apply(chr_to_num)\n",
    "    \n",
    "    # Sort by chromosome\n",
    "    df = df.sort_values(by='chr')\n",
    "\n",
    "    # Split into list of DataFrames by chromosome\n",
    "    xs_list = [group for _, group in df.groupby('chr')]\n",
    "\n",
    "    gene_lists = []\n",
    "    ys_list = []\n",
    "    xs_numpy = []\n",
    "    ys_numpy = []\n",
    "    chroms = []\n",
    "\n",
    "    for i, df_chr in enumerate(xs_list):\n",
    "        gene_list = df_chr.pop('gene_name').tolist()  # extract gene_name\n",
    "        y = df_chr.pop('gex').tolist()     \n",
    "        chroms.append(df_chr['chr'].iloc[0])         # extract target values\n",
    "        df_chr = df_chr.drop(columns=['chr'])         # remove chr column\n",
    "        xs_list[i] = df_chr                            # update the list\n",
    "        gene_lists.append(gene_list)                  # store gene names\n",
    "        ys_list.append(y)                              # store target values\n",
    "\n",
    "        # Convert DataFrame to numpy array (TSS Start and TSS End only)\n",
    "        xs_numpy.append(df_chr.to_numpy())\n",
    "        # Convert target list to numpy array\n",
    "        ys_numpy.append(np.array(y))\n",
    "\n",
    "    return xs_numpy, ys_numpy, gene_lists, chroms\n",
    "\n",
    "#Cage data\n",
    "cage_path = r'Data/CAGE-train/'  # raw string or forward slashes\n",
    "\n",
    "train_x1 = pd.read_csv(cage_path + 'X1_train_info.tsv', sep='\\t', usecols=[0,1,4,5,6])\n",
    "train_y1 = pd.read_csv(cage_path + 'X1_train_y.tsv', sep='\\t')\n",
    "valid_x1 = pd.read_csv(cage_path + 'X1_val_info.tsv', sep='\\t', usecols=[0,1,4,5,6])\n",
    "valid_y1 = pd.read_csv(cage_path + 'X1_val_y.tsv', sep='\\t')\n",
    "train_x2 = pd.read_csv(cage_path + 'X2_train_info.tsv', sep='\\t', usecols=[0,1,4,5,6])\n",
    "train_y2 = pd.read_csv(cage_path + 'X2_train_y.tsv', sep='\\t')\n",
    "valid_x2 = pd.read_csv(cage_path + 'X2_val_info.tsv', sep='\\t', usecols=[0,1,4,5,6])\n",
    "valid_y2 = pd.read_csv(cage_path + 'X2_val_y.tsv', sep='\\t')\n",
    "test_x = pd.read_csv(cage_path + 'X3_test_info.tsv', sep='\\t', usecols=[0,1,4,5,6])\n",
    "\n",
    "t_x1, t_y1, t_names1, t_chroms1 = process_dataframe(train_x1, train_y1)\n",
    "t_x2, t_y2, t_names2, t_chroms2 = process_dataframe(train_x2, train_y2)\n",
    "\n",
    "train_x = t_x1 + t_x2\n",
    "train_y = t_y1 + t_y2\n",
    "train_names = t_names1 + t_names2\n",
    "\n",
    "v_x1, v_y1, v_names1, v_chroms1 = process_dataframe(valid_x1, valid_y1)\n",
    "v_x2, v_y2, v_names2, v_chroms2 = process_dataframe(valid_x2, valid_y2)\n",
    "\n",
    "valid_x = v_x1 + v_x2\n",
    "valid_y = v_y1 + v_y2\n",
    "valid_names = v_names1 + v_names2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b317b427",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyBigWig\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "0a442d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "half_window = int(parameters.SIGNAL_CNN_WINDOW // 2)\n",
    "chromstrs = []\n",
    "ranges = []\n",
    "\n",
    "\n",
    "def get_signals_bins(df, cell_type):\n",
    "    df[\"neg_strand\"] = mask = df['strand'] == '-'\n",
    "    df.loc[mask, ['TSS_start', 'TSS_end']] = df.loc[mask, ['TSS_end', 'TSS_start']].values\n",
    "    df[\"center\"] = ((df[\"TSS_start\"] + df[\"TSS_end\"]) // 2).astype(int)\n",
    "    df[\"window_start\"] = df[\"center\"] - half_window\n",
    "    df[\"window_end\"] = df[\"center\"] + half_window\n",
    "    # df.loc[mask, ['window_start', 'window_end']] = df.loc[mask, ['window_end', 'window_start']].values\n",
    "    # df.drop(columns=['strand', 'TSS_start', 'TSS_end', 'neg_strand', 'center'], inplace=True)\n",
    "\n",
    "    bins_signal_gene = np.zeros((len(df), len(parameters.SIGNALS_CNN), parameters.CNN_N_BINS))\n",
    "    for i, signal in enumerate(parameters.SIGNALS_CNN):\n",
    "        print(\"Processing signal:\", signal, f\"{i+1}/{len(parameters.SIGNALS_CNN)}\")\n",
    "\n",
    "        for j, (chromstr, window_start, window_end, neg_strand) in enumerate(tqdm(df[[\"chr\", \"window_start\", \"window_end\", \"neg_strand\"]].itertuples(index=False), total=len(df))):\n",
    "            fname = glob.glob(f\"Data/bigwig/{signal}-bigwig/{cell_type}*\")[0]\n",
    "            bw = pyBigWig.open(fname)\n",
    "            # print(chromstr, ranges[0][0], ranges[0][1])\n",
    "            bins = bw.stats(chromstr, window_start, window_end, type=\"mean\", nBins=parameters.CNN_N_BINS)\n",
    "            if neg_strand:\n",
    "                bins = bins[::-1]\n",
    "            bins_signal_gene[j, i] = bins\n",
    "            # print(chr_i + 1, x, y)\n",
    "            bw.close()\n",
    "            \n",
    "    return bins_signal_gene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1eeabdfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing signal: DNase 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14310/14310 [00:48<00:00, 294.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing signal: H3K4me1 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14310/14310 [04:34<00:00, 52.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing signal: H3K4me3 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14310/14310 [04:39<00:00, 51.21it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing signal: H3K27ac 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14310/14310 [03:09<00:00, 75.39it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing signal: H3K36me3 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14310/14310 [06:12<00:00, 38.37it/s]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('./Data/CAGE-train/X2_train_info.tsv', sep='\\t', usecols=[0,1,4,5,6])\n",
    "signal_bins_X2_train = get_signals_bins(df, \"X2\")\n",
    "np.save('Data/processed/cnn_input_X2_train.npy', signal_bins_X2_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "877a541c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing signal: DNase 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1974/1974 [00:03<00:00, 514.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing signal: H3K4me1 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1974/1974 [00:10<00:00, 183.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing signal: H3K4me3 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1974/1974 [00:14<00:00, 137.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing signal: H3K27ac 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1974/1974 [00:19<00:00, 101.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing signal: H3K36me3 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1974/1974 [00:19<00:00, 103.35it/s]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('./Data/CAGE-train/X1_val_info.tsv', sep='\\t', usecols=[0,1,4,5,6])\n",
    "signal_bins_X1_val = get_signals_bins(df, \"X1\")\n",
    "np.save('Data/processed/cnn_input_X1_val.npy', signal_bins_X1_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "63c43025",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing signal: DNase 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1974/1974 [00:08<00:00, 233.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing signal: H3K4me1 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1974/1974 [00:32<00:00, 61.26it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing signal: H3K4me3 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1974/1974 [00:42<00:00, 46.52it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing signal: H3K27ac 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1974/1974 [00:19<00:00, 99.90it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing signal: H3K36me3 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1974/1974 [00:23<00:00, 82.96it/s] \n"
     ]
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv('./Data/CAGE-train/X2_val_info.tsv', sep='\\t', usecols=[0,1,4,5,6])\n",
    "signal_bins_X2_val = get_signals_bins(df, \"X2\")\n",
    "np.save('Data/processed/cnn_input_X2_val.npy', signal_bins_X2_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "4c8cfc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val = {}\n",
    "for cell_type in [\"X1\", \"X2\"]:\n",
    "    val_df = pd.read_csv(f\"Data/CAGE-train/{cell_type}_val_y.tsv\", sep=\"\\t\") #, index_col=\"gene_name\")\n",
    "    values = np.array(val_df[\"gex\"].values)\n",
    "    np.save(f\"Data/processed/{cell_type}_val_y.npy\", values)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml4g",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
