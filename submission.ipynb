{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries that are required to run your project\n",
    "# You are allowed to add more libraries as you need\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import spearmanr\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pyBigWig\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "import random\n",
    "import os\n",
    "from IPython.display import clear_output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Work Package 1.1 - Modeling Choices & Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIGNALS_CNN = ['DNase', 'H3K4me1', 'H3K4me3', 'H3K27ac', 'H3K36me3']   # List of signal tracks to be used\n",
    "N_SIGNALS_CNN = len(SIGNALS_CNN)\n",
    "SIGNAL_CNN_WINDOW = 1e4 # Window size in base pairs\n",
    "N_BINS = 100 # Number of base pairs per bin\n",
    "PREPROCESSED_BASE_PATH = \"Data/preprocessed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import signal\n",
    "\n",
    "\n",
    "half_window = int(SIGNAL_CNN_WINDOW // 2)\n",
    "chromstrs = []\n",
    "ranges = []\n",
    "\n",
    "\n",
    "def get_signals_bins(df: pd.DataFrame, cell_type: str, n_bins: int=N_BINS) -> np.ndarray:\n",
    "    df[\"neg_strand\"] = mask = df['strand'] == '-'\n",
    "    df.loc[mask, ['TSS_start', 'TSS_end']] = df.loc[mask, ['TSS_end', 'TSS_start']].values\n",
    "    df[\"center\"] = ((df[\"TSS_start\"] + df[\"TSS_end\"]) // 2).astype(int)\n",
    "    df[\"window_start\"] = df[\"center\"] - half_window\n",
    "    df[\"window_end\"] = df[\"center\"] + half_window\n",
    "\n",
    "    bins_signal_gene = np.zeros((len(df), len(SIGNALS_CNN), N_BINS))\n",
    "    for i, signal in enumerate(SIGNALS_CNN):\n",
    "        print(\"Processing signal:\", signal, f\"{i+1}/{len(SIGNALS_CNN)}\")\n",
    "        fname = glob.glob(f\"Data/bigwig/{signal}-bigwig/{cell_type}*\")[0]\n",
    "        bw = pyBigWig.open(fname)\n",
    "        for j, (chromstr, window_start, window_end, neg_strand) in enumerate(tqdm(df[[\"chr\", \"window_start\", \"window_end\", \"neg_strand\"]].itertuples(index=False), total=len(df))):\n",
    "            bins = bw.stats(chromstr, window_start, window_end, type=\"mean\", nBins=n_bins)\n",
    "            if neg_strand:\n",
    "                bins = bins[::-1]\n",
    "            bins_signal_gene[j, i] = bins\n",
    "\n",
    "        bw.close()\n",
    "            \n",
    "    return bins_signal_gene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing train set.\n",
      "Processing cell type: X1\n",
      "Processing signal: DNase 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14310/14310 [00:19<00:00, 722.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing signal: H3K4me1 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 5310/14310 [00:27<00:45, 196.43it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mProcessing cell type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcell_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     11\u001b[39m df = pd.read_csv(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33m./Data/CAGE-train/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcell_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_test_val\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_info.tsv\u001b[39m\u001b[33m'\u001b[39m, sep=\u001b[33m'\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[33m'\u001b[39m, usecols=[\u001b[32m0\u001b[39m,\u001b[32m1\u001b[39m,\u001b[32m4\u001b[39m,\u001b[32m5\u001b[39m,\u001b[32m6\u001b[39m])\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m signal_bins = \u001b[43mget_signals_bins\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcell_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_bins\u001b[49m\u001b[43m=\u001b[49m\u001b[43mN_BINS\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m np.save(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mPREPROCESSED_BASE_PATH\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/cnn_input_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcell_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_test_val\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mN_BINS\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.npy\u001b[39m\u001b[33m'\u001b[39m, signal_bins)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 22\u001b[39m, in \u001b[36mget_signals_bins\u001b[39m\u001b[34m(df, cell_type, n_bins)\u001b[39m\n\u001b[32m     20\u001b[39m bw = pyBigWig.open(fname)\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m j, (chromstr, window_start, window_end, neg_strand) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(tqdm(df[[\u001b[33m\"\u001b[39m\u001b[33mchr\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mwindow_start\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mwindow_end\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mneg_strand\u001b[39m\u001b[33m\"\u001b[39m]].itertuples(index=\u001b[38;5;28;01mFalse\u001b[39;00m), total=\u001b[38;5;28mlen\u001b[39m(df))):\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m     bins = \u001b[43mbw\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstats\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchromstr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwindow_start\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwindow_end\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmean\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnBins\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_bins\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     23\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m neg_strand:\n\u001b[32m     24\u001b[39m         bins = bins[::-\u001b[32m1\u001b[39m]\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "cell_types_per_set = {\n",
    "    \"train\": [\"X1\", \"X2\"],\n",
    "    \"val\": [\"X1\", \"X2\"],\n",
    "    \"test\": [\"X3\"]\n",
    "}\n",
    "\n",
    "for train_test_val, cell_types in cell_types_per_set.items():\n",
    "    print(f\"Processing {train_test_val} set.\")\n",
    "    for cell_type in cell_types:\n",
    "        print(f\"Processing cell type: {cell_type}\")\n",
    "        df = pd.read_csv(f'./Data/CAGE-train/{cell_type}_{train_test_val}_info.tsv', sep='\\t', usecols=[0,1,4,5,6])\n",
    "        signal_bins = get_signals_bins(df, cell_type, n_bins=N_BINS)\n",
    "        np.save(f'{PREPROCESSED_BASE_PATH}/cnn_input_{cell_type}_{train_test_val}_{N_BINS}.npy', signal_bins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group the data for training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_test_val, cell_types in cell_types_per_set.items():\n",
    "    all_data = []\n",
    "    for cell_type in cell_types:\n",
    "        data = np.load(f'{PREPROCESSED_BASE_PATH}/cnn_input_{cell_type}_{train_test_val}_{CNN_N_BINS}.npy')\n",
    "        all_data.append(data)\n",
    "    grouped = np.concatenate(all_data, axis=0)\n",
    "    np.save(f\"{PREPROCESSED_BASE_PATH}/cnn_input_{train_test_val}.npy\", grouped)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the same with the outputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_test_val, cell_types in cell_types_per_set.items():\n",
    "    if train_test_val == \"test\":\n",
    "        continue\n",
    "    all_y = []\n",
    "    for cell_type in cell_types:\n",
    "        y_df = pd.read_csv(f\"Data/CAGE-train/{cell_type}_{train_test_val}_y.tsv\", sep=\"\\t\")\n",
    "        all_y.append(y_df[\"gex\"].to_numpy())\n",
    "    np.save(f\"{PREPROCESSED_BASE_PATH}/cnn_y_{train_test_val}.npy\", np.concatenate(all_y, axis=0))       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Work Package 1.2 - Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model used to estimate the gene expression from binned signal is the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeneCNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv1d(N_SIGNALS_CNN, 32, kernel_size=3, padding=\"same\"),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=2),\n",
    "            nn.Conv1d(32, 16, kernel_size=3, padding=\"same\"),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=2),\n",
    "            nn.Conv1d(16, 1, kernel_size=3, padding=\"same\"),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.LazyLinear(1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: (batch, features=2, genes)\n",
    "        out = self.net(x)\n",
    "        return out.squeeze(1)  # shape: (batch, genes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model\n",
    "Since we are scoring with Spearman correlation, by which only the rank of the predicted elements is considered, we train our model to predict the $\\log(y + 1)$. This doesn't affect the score, since $\\log$ is monotonically increasing, and will help the training, given that some very high values in $y$ are difficult to model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BigWigDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.missing_val = np.any(np.isnan(X) | np.isinf(X), axis=(1,2))\n",
    "        X = X[~self.missing_val, :, :]\n",
    "        y = y[~self.missing_val]\n",
    "        self.X = torch.from_numpy(X).float()\n",
    "        self.y_orig = torch.from_numpy(y).float()\n",
    "        self.y = torch.log1p(self.y_orig)  # log(y + 1) transformation\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index], self.y[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x70e9915c82f0>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SIZE = 2056\n",
    "EPOCHS = 200\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "SAVE_BASED_ON_SPEARMAN = True\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.load(f\"{PREPROCESSED_BASE_PATH}/cnn_input_train.npy\")\n",
    "y_train = np.load(f\"{PREPROCESSED_BASE_PATH}/cnn_y_train.npy\")\n",
    "\n",
    "x_val = np.load(f\"{PREPROCESSED_BASE_PATH}/cnn_input_val.npy\")\n",
    "y_val = np.load(f\"{PREPROCESSED_BASE_PATH}/cnn_y_val.npy\")\n",
    "\n",
    "training_loader = DataLoader(\n",
    "    BigWigDataset(x_train, y_train),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "x_val_torch, y_val_torch = BigWigDataset(x_val, y_val)[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [00:02<00:00,  5.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: best 3.191025495529175 and avg 3.8869532687323436\n",
      "Validation loss: 3.4875845909118652\n",
      "Spearman's correlation: 0.6123085389396951\n",
      "Saving as best model in models/cnn_20251023_011440_SPEARMAN61.2309_BS2056_LR0.001_BIN100_W10000_EPOCH1\n",
      "Saving as best model in models/cnn_20251023_011440_VALLOSS3.4876_BS2056_LR0.001_BIN100_W10000_EPOCH1\n",
      "Epoch: 2/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [00:02<00:00,  5.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: best 2.5101592540740967 and avg 2.935048086302621\n",
      "Validation loss: 2.7209837436676025\n",
      "Spearman's correlation: 0.6614618705322575\n",
      "Saving as best model in models/cnn_20251023_011440_SPEARMAN66.1462_BS2056_LR0.001_BIN100_W10000_EPOCH2\n",
      "Saving as best model in models/cnn_20251023_011440_VALLOSS2.7210_BS2056_LR0.001_BIN100_W10000_EPOCH2\n",
      "Epoch: 3/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [00:02<00:00,  5.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: best 2.2899327278137207 and avg 2.4895146744591847\n",
      "Validation loss: 2.3924970626831055\n",
      "Spearman's correlation: 0.6954101034290064\n",
      "Saving as best model in models/cnn_20251023_011440_SPEARMAN69.5410_BS2056_LR0.001_BIN100_W10000_EPOCH3\n",
      "Saving as best model in models/cnn_20251023_011440_VALLOSS2.3925_BS2056_LR0.001_BIN100_W10000_EPOCH3\n",
      "Epoch: 4/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [00:02<00:00,  5.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: best 2.0410754680633545 and avg 2.248136452266148\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[79]\u001b[39m\u001b[32m, line 41\u001b[39m\n\u001b[32m     37\u001b[39m net.eval()\n\u001b[32m     39\u001b[39m running_vloss = \u001b[32m.0\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m pred_val = \u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_val_torch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     42\u001b[39m loss = loss_fn(pred_val.flatten(), y_val_torch)\n\u001b[32m     43\u001b[39m val_loss = loss.item()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/python/plaf/miniforge3/envs/ml4g/lib/python3.12/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/python/plaf/miniforge3/envs/ml4g/lib/python3.12/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 19\u001b[39m, in \u001b[36mGeneCNNModel.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m     18\u001b[39m     \u001b[38;5;66;03m# x shape: (batch, features=2, genes)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m     out = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     20\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m out.squeeze(\u001b[32m1\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/python/plaf/miniforge3/envs/ml4g/lib/python3.12/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/python/plaf/miniforge3/envs/ml4g/lib/python3.12/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/python/plaf/miniforge3/envs/ml4g/lib/python3.12/site-packages/torch/nn/modules/container.py:244\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    242\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[32m    243\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m244\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    245\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/python/plaf/miniforge3/envs/ml4g/lib/python3.12/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/python/plaf/miniforge3/envs/ml4g/lib/python3.12/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/python/plaf/miniforge3/envs/ml4g/lib/python3.12/site-packages/torch/nn/modules/pooling.py:145\u001b[39m, in \u001b[36mMaxPool1d.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    144\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor):\n\u001b[32m--> \u001b[39m\u001b[32m145\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmax_pool1d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    146\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    147\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkernel_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    148\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    149\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    150\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[43m        \u001b[49m\u001b[43mceil_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mceil_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    152\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_indices\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mreturn_indices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    153\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/python/plaf/miniforge3/envs/ml4g/lib/python3.12/site-packages/torch/_jit_internal.py:627\u001b[39m, in \u001b[36mboolean_dispatch.<locals>.fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    625\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m if_true(*args, **kwargs)\n\u001b[32m    626\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m627\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mif_false\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/python/plaf/miniforge3/envs/ml4g/lib/python3.12/site-packages/torch/nn/functional.py:737\u001b[39m, in \u001b[36m_max_pool1d\u001b[39m\u001b[34m(input, kernel_size, stride, padding, dilation, ceil_mode, return_indices)\u001b[39m\n\u001b[32m    735\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m stride \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    736\u001b[39m     stride = torch.jit.annotate(\u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mint\u001b[39m], [])\n\u001b[32m--> \u001b[39m\u001b[32m737\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmax_pool1d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mceil_mode\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "net = GeneCNNModel()\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=LEARNING_RATE)\n",
    "best_val_loss = float('inf')\n",
    "best_spearman_corr = float('-inf')\n",
    "spearman_model_path = None\n",
    "val_model_path = None\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "for epoch in range(EPOCHS):\n",
    "    best_loss = float(\"inf\")\n",
    "    last_loss = 0\n",
    "\n",
    "    net.train()\n",
    "\n",
    "    running_loss = .0\n",
    "    print(f\"Epoch: {epoch + 1}/{EPOCHS}\")\n",
    "    \n",
    "    for i, (X, y) in tqdm(enumerate(training_loader), total=len(training_loader)):            \n",
    "        optimizer.zero_grad()\n",
    "        pred = net(X)\n",
    "        loss = loss_fn(pred.flatten(), y)\n",
    "        \n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        batch_loss = loss.item()\n",
    "        running_loss += batch_loss\n",
    "        best_loss = min(batch_loss, best_loss)\n",
    "    \n",
    "    \n",
    "\n",
    "    avg_loss = running_loss / (i + 1)\n",
    "\n",
    "    print(f\"Training loss: best {best_loss} and avg {avg_loss}\")\n",
    "\n",
    "    net.eval()\n",
    "\n",
    "    running_vloss = .0\n",
    "\n",
    "    pred_val = net(x_val_torch)\n",
    "    loss = loss_fn(pred_val.flatten(), y_val_torch)\n",
    "    val_loss = loss.item()\n",
    "    \n",
    "    print('Validation loss: {}'.format(val_loss))\n",
    "\n",
    "    spearman_corr = spearmanr(pred_val.detach().numpy(), y_val_torch.detach().numpy()).statistic\n",
    "    print(\"Spearman's correlation:\", spearman_corr)\n",
    "    \n",
    "    def save_model(criterion: str, model_path: str | None) -> str:\n",
    "        if model_path is not None and os.path.exists(model_path):\n",
    "            os.remove(model_path)\n",
    "\n",
    "        model_path = \"models/cnn_{}_{}_BS{}_LR{}_BIN{}_W{}_EPOCH{}\".format(timestamp, criterion, BATCH_SIZE, LEARNING_RATE, int(N_BINS), int(SIGNAL_CNN_WINDOW), epoch + 1)\n",
    "\n",
    "        print(f\"Saving as best model in {model_path}\")\n",
    "        torch.save(net, model_path)\n",
    "\n",
    "        return model_path\n",
    "    \n",
    "    \n",
    "    if spearman_corr > best_spearman_corr:\n",
    "        best_spearman_corr = spearman_corr\n",
    "        if SAVE_BASED_ON_SPEARMAN:\n",
    "            spearman_model_path = save_model(\"SPEARMAN{:.4f}\".format(best_spearman_corr * 100), spearman_model_path)\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        val_model_path = save_model(\"VALLOSS{:.4f}\".format(best_val_loss), val_model_path)\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        clear_output(wait=True)\n",
    "\n",
    "print(\"Training complete. Best avg validation loss:\", best_val_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Work Package 1.3 - Prediction on Test Data (Evaluation Metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_test = np.load(f\"{PREPROCESSED_BASE_PATH}/cnn_input_test.npy\")\n",
    "\n",
    "if SAVE_BASED_ON_SPEARMAN:\n",
    "    cnn_net = torch.load(spearman_model_path, weights_only=False) # Load the best model based on Spearman correlation\n",
    "else:\n",
    "    cnn_net = torch.load(val_model_path, weights_only=False) # Load the best model based on validation loss\n",
    "\n",
    "# Or manually specify the model path:\n",
    "# cnn_net = torch.load(\"models/cnn_your_model_path_here\", weights_only=False)\n",
    "\n",
    "cnn_net.eval()\n",
    "y_test_pred = cnn_net(torch.tensor(x_test, dtype=torch.float32)).detach().numpy()\n",
    "\n",
    "test_genes = pd.read_csv('./Data/CAGE-train/X3_test_info.tsv', sep='\\t', usecols=[0,1])\n",
    "test_genes['gex_predicted'] = np.exp(y_test_pred.flatten()) - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Store Predictions in the Required Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store predictions in a ZIP. \n",
    "# Upload this zip on the project website under \"Your submission\".\n",
    "# Zip this notebook along with the conda environment (and README, optional) and upload this under \"Your code\".\n",
    "\n",
    "save_dir = 'Data/submission'\n",
    "file_name = 'gex_predicted.csv'         # PLEASE DO NOT CHANGE THIS\n",
    "zip_name = \"Laffranchi_Paolo_Project1.zip\"\n",
    "save_path = f'{save_dir}/{zip_name}'\n",
    "compression_options = dict(method=\"zip\", archive_name=file_name)\n",
    "\n",
    "test_genes[['gene_name', 'gex_predicted']].to_csv(save_path, compression=compression_options)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml4g",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
