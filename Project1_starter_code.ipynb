{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries that are required to run your project\n",
    "# You are allowed to add more libraries as you need\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import spearmanr\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pyBigWig\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "import random\n",
    "import os\n",
    "from IPython.display import clear_output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Work Package 1.1 - Modeling Choices & Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIGNALS_CNN = ['DNase', 'H3K4me1', 'H3K4me3', 'H3K27ac', 'H3K36me3']   # List of signal tracks to be used\n",
    "N_SIGNALS_CNN = len(SIGNALS_CNN)\n",
    "SIGNAL_CNN_WINDOW = 1e4 # Window size in base pairs\n",
    "N_BINS = 100 # Number of base pairs per bin\n",
    "PREPROCESSED_BASE_PATH = \"Data/preprocessed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "half_window = int(SIGNAL_CNN_WINDOW // 2)\n",
    "chromstrs = []\n",
    "ranges = []\n",
    "\n",
    "\n",
    "def get_signals_bins(df: pd.DataFrame, cell_type: str, n_bins: int=N_BINS) -> np.ndarray:\n",
    "    df[\"neg_strand\"] = mask = df['strand'] == '-'\n",
    "    df.loc[mask, ['TSS_start', 'TSS_end']] = df.loc[mask, ['TSS_end', 'TSS_start']].values\n",
    "    df[\"center\"] = ((df[\"TSS_start\"] + df[\"TSS_end\"]) // 2).astype(int)\n",
    "    df[\"window_start\"] = df[\"center\"] - half_window\n",
    "    df[\"window_end\"] = df[\"center\"] + half_window\n",
    "\n",
    "    bins_signal_gene = np.zeros((len(df), len(SIGNALS_CNN), N_BINS))\n",
    "    for i, signal in enumerate(SIGNALS_CNN):\n",
    "        print(\"Processing signal:\", signal, f\"{i+1}/{len(SIGNALS_CNN)}\")\n",
    "\n",
    "        for j, (chromstr, window_start, window_end, neg_strand) in enumerate(tqdm(df[[\"chr\", \"window_start\", \"window_end\", \"neg_strand\"]].itertuples(index=False), total=len(df))):\n",
    "            fname = glob.glob(f\"Data/bigwig/{signal}-bigwig/{cell_type}*\")[0]\n",
    "            bw = pyBigWig.open(fname)\n",
    "\n",
    "            bins = bw.stats(chromstr, window_start, window_end, type=\"mean\", nBins=n_bins)\n",
    "            if neg_strand:\n",
    "                bins = bins[::-1]\n",
    "            bins_signal_gene[j, i] = bins\n",
    "\n",
    "            bw.close()\n",
    "            \n",
    "    return bins_signal_gene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_types_per_set = {\n",
    "    \"train\": [\"X1\", \"X2\"],\n",
    "    \"val\": [\"X1\", \"X2\"],\n",
    "    \"test\": [\"X3\"]\n",
    "}\n",
    "\n",
    "for train_test_val, cell_types in cell_types_per_set.items():\n",
    "    print(f\"Processing {train_test_val} set.\")\n",
    "    for cell_type in cell_types:\n",
    "        print(f\"Processing cell type: {cell_type}\")\n",
    "        df = pd.read_csv(f'./Data/CAGE-train/{cell_type}_{train_test_val}_info.tsv', sep='\\t', usecols=[0,1,4,5,6])\n",
    "        signal_bins = get_signals_bins(df, cell_type, n_bins=N_BINS)\n",
    "        np.save(f'{PREPROCESSED_BASE_PATH}/cnn_input_{cell_type}_{train_test_val}_{N_BINS}.npy', signal_bins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group the data for training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_test_val, cell_types in cell_types_per_set.items():\n",
    "    all_data = []\n",
    "    for cell_type in cell_types:\n",
    "        data = np.load(f'{PREPROCESSED_BASE_PATH}/cnn_input_{cell_type}_{train_test_val}_{CNN_N_BINS}.npy')\n",
    "        all_data.append(data)\n",
    "    grouped = np.concatenate(all_data, axis=0)\n",
    "    np.save(f\"{PREPROCESSED_BASE_PATH}/cnn_input_{train_test_val}.npy\", grouped)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the same with the outputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_test_val, cell_types in cell_types_per_set.items():\n",
    "    if train_test_val == \"test\":\n",
    "        continue\n",
    "    all_y = []\n",
    "    for cell_type in cell_types:\n",
    "        y_df = pd.read_csv(f\"Data/CAGE-train/{cell_type}_{train_test_val}_y.tsv\", sep=\"\\t\")\n",
    "        all_y.append(y_df[\"gex\"].to_numpy())\n",
    "    np.save(f\"{PREPROCESSED_BASE_PATH}/cnn_y_{train_test_val}.npy\", np.concatenate(all_y, axis=0))       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Work Package 1.2 - Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model used to estimate the gene expression from binned signal is the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeneCNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv1d(N_SIGNALS_CNN, 32, kernel_size=3, padding=\"same\"),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=2),\n",
    "            nn.Conv1d(32, 16, kernel_size=3, padding=\"same\"),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=2),\n",
    "            nn.Conv1d(16, 1, kernel_size=3, padding=\"same\"),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.LazyLinear(1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: (batch, features=2, genes)\n",
    "        out = self.net(x)\n",
    "        return out.squeeze(1)  # shape: (batch, genes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model\n",
    "Since we are scoring with Pearson's R, by which only the rank of the predicted elements is considered, we train our model to predict the $\\log(y + 1)$. This doesn't affect the score, since $\\log$ is monotonically increasing, and will help the training, given that some very high values in $y$ are difficult to model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BigWigDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.missing_val = np.any(np.isnan(X) | np.isinf(X), axis=(1,2))\n",
    "        X = X[~self.missing_val, :, :]\n",
    "        y = y[~self.missing_val]\n",
    "        self.X = torch.from_numpy(X).float()\n",
    "        self.y_orig = torch.from_numpy(y).float()\n",
    "        self.y = torch.log1p(self.y_orig)  # log(y + 1) transformation\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index], self.y[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x70e9915c82f0>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SIZE = 2056\n",
    "EPOCHS = 200\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.load(f\"{PREPROCESSED_BASE_PATH}/cnn_input_train.npy\")\n",
    "y_train = np.load(f\"{PREPROCESSED_BASE_PATH}/cnn_y_train.npy\")\n",
    "\n",
    "x_val = np.load(f\"{PREPROCESSED_BASE_PATH}/cnn_input_val.npy\")\n",
    "y_val = np.load(f\"{PREPROCESSED_BASE_PATH}/cnn_y_val.npy\")\n",
    "\n",
    "training_loader = DataLoader(\n",
    "    BigWigDataset(x_train, y_train),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "validation_loader = DataLoader(\n",
    "    BigWigDataset(x_val, y_val),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 21/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [00:02<00:00,  5.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: best 1.4061312675476074 and avg 1.563666548047747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 15.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg valid loss: 1.478577733039856\n",
      "Saving as best model in models/cnn_20251021_014810_VLOSS1.4786_BS2056_LR0.001_BIN100_W10000\n",
      "Epoch: 22/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [00:02<00:00,  6.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: best 1.4650572538375854 and avg 1.5372563770839147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 15.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg valid loss: 1.482599675655365\n",
      "Epoch: 23/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [00:02<00:00,  6.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: best 1.373448133468628 and avg 1.5304521662848336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 16.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg valid loss: 1.6006670594215393\n",
      "Epoch: 24/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [00:02<00:00,  6.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: best 1.4478486776351929 and avg 1.5400898797171456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 15.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg valid loss: 1.4993081092834473\n",
      "Epoch: 25/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [00:02<00:00,  5.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: best 1.3726978302001953 and avg 1.510515911238534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 12.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg valid loss: 1.5343226194381714\n",
      "Epoch: 26/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [00:02<00:00,  5.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: best 1.3330895900726318 and avg 1.4856048652103968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 14.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg valid loss: 1.49180006980896\n",
      "Epoch: 27/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████▏  | 10/14 [00:01<00:00,  5.58it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[60]\u001b[39m\u001b[32m, line 22\u001b[39m\n\u001b[32m     19\u001b[39m y_hat = net(X)\n\u001b[32m     20\u001b[39m loss = loss_fn(y_hat.flatten(), y)\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     24\u001b[39m optimizer.step()\n\u001b[32m     25\u001b[39m batch_loss = loss.item()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/python/plaf/miniforge3/envs/ml4g/lib/python3.12/site-packages/torch/_tensor.py:647\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    637\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    638\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    639\u001b[39m         Tensor.backward,\n\u001b[32m    640\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    645\u001b[39m         inputs=inputs,\n\u001b[32m    646\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m647\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    648\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    649\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/python/plaf/miniforge3/envs/ml4g/lib/python3.12/site-packages/torch/autograd/__init__.py:354\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    349\u001b[39m     retain_graph = create_graph\n\u001b[32m    351\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    352\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    353\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m354\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_tuple\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    362\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/python/plaf/miniforge3/envs/ml4g/lib/python3.12/site-packages/torch/autograd/graph.py:829\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    827\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    828\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m829\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    830\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    831\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    832\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    833\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "net = GeneCNNModel()\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=LEARNING_RATE)\n",
    "best_val_loss = float('inf')\n",
    "model_path = None\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "for epoch in range(EPOCHS):\n",
    "    best_loss = float(\"inf\")\n",
    "    last_loss = 0\n",
    "\n",
    "    net.train()\n",
    "\n",
    "    running_loss = .0\n",
    "    print(f\"Epoch: {epoch + 1}/{EPOCHS}\")\n",
    "    \n",
    "    for i, (X, y) in tqdm(enumerate(training_loader), total=len(training_loader)):            \n",
    "        optimizer.zero_grad()\n",
    "        y_hat = net(X)\n",
    "        loss = loss_fn(y_hat.flatten(), y)\n",
    "        \n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        batch_loss = loss.item()\n",
    "        running_loss += batch_loss\n",
    "        best_loss = min(batch_loss, best_loss)\n",
    "    \n",
    "    \n",
    "\n",
    "    avg_loss = running_loss / (i + 1)\n",
    "\n",
    "    print(f\"Training loss: best {best_loss} and avg {avg_loss}\")\n",
    "\n",
    "    net.eval()\n",
    "\n",
    "    running_vloss = .0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (X, y) in tqdm(enumerate(validation_loader), total=len(validation_loader)):\n",
    "            y_hat = net(X)\n",
    "            loss = loss_fn(y_hat.flatten(), y)\n",
    "            running_vloss += loss.item()\n",
    "    \n",
    "    avg_val_loss = running_vloss / (i + 1)\n",
    "    print('Avg valid loss: {}'.format(avg_val_loss))\n",
    "\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        if model_path and os.path.exists(model_path):\n",
    "            os.remove(model_path)\n",
    "\n",
    "        best_val_loss = avg_val_loss\n",
    "\n",
    "        model_path = \"models/cnn_{}_VLOSS{:.4f}_BS{}_LR{}_BIN{}_W{}\".format(timestamp, best_val_loss, BATCH_SIZE, LEARNING_RATE, int(N_BINS), int(SIGNAL_CNN_WINDOW))\n",
    "\n",
    "        print(f\"Saving as best model in {model_path}\")\n",
    "        torch.save(net, model_path)\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        clear_output(wait=True)\n",
    "\n",
    "print(\"Training complete. Best avg validation loss:\", best_val_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Work Package 1.3 - Prediction on Test Data (Evaluation Metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------INSERT CODE HERE---------------------------\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "\n",
    "# Check if \"pred\" meets the specified constrains\n",
    "assert isinstance(pred, np.ndarray), 'Prediction array must be a numpy array'\n",
    "assert np.issubdtype(pred.dtype, np.number), 'Prediction array must be numeric'\n",
    "assert pred.shape[0] == len(test_genes), 'Each gene should have a unique predicted expression'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()  # Set the model to evaluation mode\n",
    "preds = []\n",
    "for X_chr, y_chr in zip(train_x, train_y):\n",
    "    # Convert numpy arrays to torch tensors\n",
    "    X_chr = torch.tensor(X_chr.T, dtype=torch.float32).unsqueeze(0)  # (1, 2, num_genes)\n",
    "    y_chr = torch.tensor(y_chr, dtype=torch.float32).unsqueeze(0)    # (1, num_genes)\n",
    "\n",
    "    preds.append(model(X_chr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to numpy if tensor\n",
    "pred_values = preds[0].detach().cpu().numpy().ravel()  # assuming same chromosome index\n",
    "gene_names_chr = train_names[0]  # assuming same chromosome index\n",
    "\n",
    "# Build DataFrame\n",
    "df_pred = pd.DataFrame({\n",
    "    'gene_name': gene_names_chr,\n",
    "    'prediction': pred_values\n",
    "})\n",
    "\n",
    "print(df_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Store Predictions in the Required Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store predictions in a ZIP. \n",
    "# Upload this zip on the project website under \"Your submission\".\n",
    "# Zip this notebook along with the conda environment (and README, optional) and upload this under \"Your code\".\n",
    "\n",
    "save_dir = 'Data/submission'  # TODO\n",
    "file_name = 'gex_predicted.csv'         # PLEASE DO NOT CHANGE THIS\n",
    "zip_name = \"Laffranchi_Paolo_Project1.zip\" # TODO\n",
    "save_path = f'{save_dir}/{zip_name}'\n",
    "compression_options = dict(method=\"zip\", archive_name=file_name)\n",
    "\n",
    "test_genes = pd.read_csv(f\"{save_dir}/{file_name}\")\n",
    "test_genes[['gene_name', 'gex_predicted']].to_csv(save_path, compression=compression_options)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml4g",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
